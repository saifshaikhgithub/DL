{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c380a7ab-3fba-465d-9297-42d0abf3c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accordion', 'airplanes', 'anchor', 'ant', 'BACKGROUND_Google', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'Faces', 'Faces_easy', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'Leopards', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'Motorbikes', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_dir = os.path.join(r'C:\\Users\\Saif\\Downloads\\LP-IV-datasets\\LP-IV-datasets\\Object Detection(Ass6)', 'caltech-101-img')\n",
    "print(os.listdir(dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18e3d592-192c-4c9d-a795-834bce436e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8f95975-cfa7-4423-bb42-c42e3bace0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1.0/255.,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c30b102-4219-4010-a292-e44b0a1bddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6903 images belonging to 102 classes.\n",
      "Found 2241 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "tg=datagen.flow_from_directory(dataset_dir,target_size=(64,64),batch_size=2000,class_mode='categorical',subset='training')\n",
    "vg=datagen.flow_from_directory(dataset_dir,target_size=(64,64),batch_size=2000,class_mode='categorical',subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ec99ab9-6ed8-484b-88e0-5fd12af2a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=tg[0]\n",
    "x_test,y_test=vg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d52d44c-3bda-4906-a855-456439082771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 64, 64, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a273051-1b55-487a-897f-c00bf6746c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 102)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fbcb3b8-74d4-4075-941b-cbbd77d6baa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = r'C:\\Users\\Saif\\Downloads\\LP-IV-datasets\\LP-IV-datasets\\Object Detection(Ass6)\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6244ceec-19f8-464a-9b55-bc27198d85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0101458-790d-45fc-bacb-a2f2bde38026",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76ed7150-c717-4e70-8834-bcf26853eaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BACKGROUND_Google': 0, 'Faces': 1, 'Faces_easy': 2, 'Leopards': 3, 'Motorbikes': 4, 'accordion': 5, 'airplanes': 6, 'anchor': 7, 'ant': 8, 'barrel': 9, 'bass': 10, 'beaver': 11, 'binocular': 12, 'bonsai': 13, 'brain': 14, 'brontosaurus': 15, 'buddha': 16, 'butterfly': 17, 'camera': 18, 'cannon': 19, 'car_side': 20, 'ceiling_fan': 21, 'cellphone': 22, 'chair': 23, 'chandelier': 24, 'cougar_body': 25, 'cougar_face': 26, 'crab': 27, 'crayfish': 28, 'crocodile': 29, 'crocodile_head': 30, 'cup': 31, 'dalmatian': 32, 'dollar_bill': 33, 'dolphin': 34, 'dragonfly': 35, 'electric_guitar': 36, 'elephant': 37, 'emu': 38, 'euphonium': 39, 'ewer': 40, 'ferry': 41, 'flamingo': 42, 'flamingo_head': 43, 'garfield': 44, 'gerenuk': 45, 'gramophone': 46, 'grand_piano': 47, 'hawksbill': 48, 'headphone': 49, 'hedgehog': 50, 'helicopter': 51, 'ibis': 52, 'inline_skate': 53, 'joshua_tree': 54, 'kangaroo': 55, 'ketch': 56, 'lamp': 57, 'laptop': 58, 'llama': 59, 'lobster': 60, 'lotus': 61, 'mandolin': 62, 'mayfly': 63, 'menorah': 64, 'metronome': 65, 'minaret': 66, 'nautilus': 67, 'octopus': 68, 'okapi': 69, 'pagoda': 70, 'panda': 71, 'pigeon': 72, 'pizza': 73, 'platypus': 74, 'pyramid': 75, 'revolver': 76, 'rhino': 77, 'rooster': 78, 'saxophone': 79, 'schooner': 80, 'scissors': 81, 'scorpion': 82, 'sea_horse': 83, 'snoopy': 84, 'soccer_ball': 85, 'stapler': 86, 'starfish': 87, 'stegosaurus': 88, 'stop_sign': 89, 'strawberry': 90, 'sunflower': 91, 'tick': 92, 'trilobite': 93, 'umbrella': 94, 'watch': 95, 'water_lilly': 96, 'wheelchair': 97, 'wild_cat': 98, 'windsor_chair': 99, 'wrench': 100, 'yin_yang': 101}\n"
     ]
    }
   ],
   "source": [
    "print(tg.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56e5fdec-d095-48f6-8334-311d7e3f3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Flatten()(base_model.output)\n",
    "x=Dense(64,activation='relu')(x)\n",
    "x=Dense(90,activation='relu')(x)\n",
    "preds=Dense(102,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5747563-5b67-49c6-9ee9-a538535fea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3771cf8d-ce52-48f1-a4be-82f2e6c13cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aaeab3-e5cb-4a41-a670-3b0fd9162983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.1438 - loss: 4.1317 - val_accuracy: 0.3255 - val_loss: 3.1182\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.3801 - loss: 2.8115 - val_accuracy: 0.4485 - val_loss: 2.5343\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.5206 - loss: 2.0815 - val_accuracy: 0.5050 - val_loss: 2.2141\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.6236 - loss: 1.5855 - val_accuracy: 0.5395 - val_loss: 2.0584\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.6938 - loss: 1.2497 - val_accuracy: 0.5540 - val_loss: 1.9874\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.7760 - loss: 0.9792 - val_accuracy: 0.5650 - val_loss: 1.9426\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.8149 - loss: 0.8033 - val_accuracy: 0.5610 - val_loss: 1.9675\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.8574 - loss: 0.6159 - val_accuracy: 0.5780 - val_loss: 1.9166\n",
      "Epoch 9/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 1s/step - accuracy: 0.8969 - loss: 0.4949 - val_accuracy: 0.5865 - val_loss: 1.9084\n",
      "Epoch 10/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725ms/step - accuracy: 0.9228 - loss: 0.3739"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2da70-6a08-40d5-8100-6699daace7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
